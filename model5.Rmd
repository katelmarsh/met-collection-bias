# [Model 5]

## neural network 




```{r}
library(keras)
library(dplyr)
train_dat <- read.csv("train_dat_cleaned.csv")
test_dat <- read.csv("test_dat_cleaned.csv")

train_dat2 <- train_dat %>% select(-c(X.2, grp1, grp2, grp3, X))
test_dat2 <- test_dat %>% select(-c(X.2, grp1, grp2, grp3, X))

x_train <- as.matrix(train_dat2[, -which(names(train_dat2) == "is.highlightTrue")])
y_train <- as.matrix(train_dat2$is.highlightTrue)
x_test <- as.matrix(test_dat2[, -which(names(test_dat2) == "is.highlightTrue")])
y_test <- as.matrix(test_dat2$is.highlightTrue)

# Define the model architecture
model <- keras_model_sequential() %>% 
  layer_dense(units = 64, activation = "relu", input_shape = ncol(x_train)) %>% 
  layer_dense(units = 32, activation = "relu") %>% 
  layer_dense(units = 1, activation = "sigmoid")

# Compile the model with a loss function, optimizer, and metric
history <- model %>% compile(
  loss = "binary_crossentropy",
  optimizer = "adam",
  metrics = c("accuracy")
)

# Train the model on the training data
model %>% fit(
  x_train, y_train,
  validation_split = 0.2,
  epochs = 100,
  batch_size = 5
)


# Evaluate the model on the test data
metrics <- model %>% evaluate(x_test, y_test)

# Print the test accuracy
cat("Test accuracy:", metrics["accuracy"], "\n")
```

It got every label in the test set right after 10 epochs. 


###To interpret this model, we will use Shapley Values: 

According to "9.6 SHAP (SHapley Additive exPlanations)" from our IML textbook (https://christophm.github.io/interpretable-ml-book/shap.html): 
    Shapley values are "The Shapley value, coined by Shapley (1953), is a method for assigning payouts to players depending on their contribution to the total payout. Players cooperate in a coalition and receive a certain profit from this cooperation". The math for SHAP is as follows: g(z')=\phi_0+\sum_{j=1}^M\phi_jz_j' where where g is the explanation model, z'\in\{0,1\}^M is the coalition vector, M is the maximum coalition size and \phi_j\in\mathbb{R} is the feature attribution for a feature j, the Shapley values. 


###Shapley Values for the First Line of the Test Dataset 
In this graph, we can see what is most imporrtnat 


```{r}
library(iml)
library(keras)

shap_train <- train_dat2[, -which(names(train_dat2) == "is.highlightTrue")]
shap_test <- test_dat2[, -which(names(test_dat2) == "is.highlightTrue")]


mod <- Predictor$new(model, data = shap_train)
x.interest <- shap_test[1,]
shapley <- Shapley$new(mod, x.interest = x.interest)
plot(shapley)

```
        
        
###Shapley Values for full Test Set 

```{r}
library(iml)

mod <- Predictor$new(model, data = shap_train)
x.interest <- shap_test[c(1:744),]
shapley <- Shapley$new(mod, x.interest = x.interest)
plot(shapley)

```
          
The value of a shapley value is the average contribution of a feature value to the prediction in different coalitions. From this, we can tell that "geography.type "MadeIn"is a positive predictor of whether something is a highlight of the Met Collection. 

```{r}
madein <- df[which(df$geography.type == "Madein"),]
country <- head(sort(table(madein$country), decreasing = TRUE), 20) 
c5_df <- as.data.frame(country)
ggplot(c5_df, aes(x = Freq, y = Var1)) + 
  geom_col() + theme_light() + ggtitle(label = "Art Country, Top 20, MadeIn Geography") 

```




